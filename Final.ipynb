{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ee8d8-434c-47b8-97e8-8ec7e46daae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fba66-8487-455d-8d24-64ddf3be2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"Soccer Betting Odds Analyzation\") \\\n",
    "      .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe32ba-91e8-4aaa-a24b-7901553a55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv files retrieved from: https://www.kaggle.com/datasets/hugomathien/soccer\n",
    "\n",
    "# read csv files into dataframes and remove first row\n",
    "leagues_df = spark.read.options(header='True', delimiter=',').csv('leagues.csv')\n",
    "matches_df = spark.read.options(header='True', delimiter=',').csv('matches.csv')\n",
    "p_att_df = spark.read.options(header='True', delimiter=',').csv('player_atts.csv')\n",
    "players_df = spark.read.options(header='True', delimiter=',').csv('players.csv')\n",
    "t_att_df = spark.read.options(header='True', delimiter=',').csv('team_atts.csv')\n",
    "teams_df = spark.read.options(header='True', delimiter=',').csv('teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0080e9-ba6d-4201-9531-f07cd9a61dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def checkMLResult(x):\n",
    "    homeWinOdds = float(x.B365H)\n",
    "    tieOdds = float(x.B365D)\n",
    "    awayWinOdds = float(x.B365A)\n",
    "\n",
    "    homeGoals = int(x.home_team_goal)\n",
    "    awayGoals = int(x.away_team_goal)\n",
    "\n",
    "    list = [str(homeWinOdds), str(tieOdds), str(awayWinOdds) ]\n",
    "    float_arr = np.array(list, dtype=float)\n",
    "    minVal = np.min(float_arr) \n",
    "    maxVal = np.max(float_arr) \n",
    "\n",
    "    if (homeGoals > awayGoals):\n",
    "        if homeWinOdds == minVal:\n",
    "            return (x.league_id + \" MIN\", 1)\n",
    "        if homeWinOdds != minVal and homeWinOdds != maxVal:\n",
    "            return (x.league_id + \" MID\", 1)\n",
    "        if homeWinOdds == maxVal:\n",
    "            return (x.league_id + \" MAX\", 1)\n",
    "    elif (homeGoals == awayGoals):\n",
    "        if tieOdds == minVal:\n",
    "            return (x.league_id + \" MIN\", 1)\n",
    "        if tieOdds != minVal and homeWinOdds != maxVal:\n",
    "            return (x.league_id + \" MID\", 1)\n",
    "        if tieOdds == maxVal:\n",
    "            return (x.league_id + \" MAX\", 1)\n",
    "    else:\n",
    "        if awayWinOdds == minVal:\n",
    "            return (x.league_id + \" MIN\", 1)\n",
    "        if awayWinOdds != minVal and homeWinOdds != maxVal:\n",
    "            return (x.league_id + \" MID\", 1)\n",
    "        if awayWinOdds == maxVal:\n",
    "            return (x.league_id + \" MAX\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653e556-180a-4d66-952b-69a8aae1bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = matches_df.where(col(\"B365H\").isNotNull())\n",
    "# create an rdd in which we map the league ID with corresponding result value\n",
    "matches_rdd = df.rdd.map(lambda x: checkMLResult(x))\n",
    "# filter out results in which the database does not have values in place\n",
    "matches_rdd = matches_rdd.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9293f-f341-4dba-aa0e-07cdf29bcc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce by key (league and 1, 2, or 3)\n",
    "result_counts = matches_rdd.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fff0d9-3dd0-436d-990e-76f1d4c4ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each record in the RDD we should take the initial string which is the league ID and divide the second index\n",
    "# by the number of matches in the matches dataframe for that league. then the one with the highest coefficient will\n",
    "# be the most common 'bang for the buck' and we will focus on the features of that league\n",
    "\n",
    "# first, transform the rdd to split the first index on the space between the league ID and min/mid/max identifier\n",
    "split_league_rdd = result_counts.map(lambda line: (line[0].split(\" \")[0], line[0].split(\" \")[1] + \" \" + str(line[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a409f-feb6-4931-ae90-8df44b5d83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an RDD in which we count the number of matches for each league ID\n",
    "def getMatches(x):\n",
    "    return(x.league_id, 1)\n",
    "\n",
    "# create an rdd in which we map the league ID with corresponding result value\n",
    "match_tot_rdd = df.rdd.map(lambda x: getMatches(x))\n",
    "# filter out results in which the database does not have values in place\n",
    "match_tot_rdd = match_tot_rdd.filter(lambda x: x is not None)\n",
    "match_totals = match_tot_rdd.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81939246-a664-456f-b3c6-49a8dc7b134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the RDDs in order to get rdd which contains first the League ID and then a tuple of odds occurence and match numbers\n",
    "join_rdd = match_totals.join(split_league_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c266316-2fc8-4fde-b799-6b052af8c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create coefficient RDD\n",
    "\n",
    "# first split the tuple of the second index\n",
    "all_elements_split_rdd = join_rdd.map(lambda line: (line[0], line[1][0], line[1][1].split(\" \")[0], int(line[1][1].split(\" \")[1])))\n",
    "\n",
    "# then divide each last element (number of matches of this type of occurrence) by the 2nd element (number of matches in this league)\n",
    "coeff_rdd = all_elements_split_rdd.map(lambda line: (line[0], line[2], float(line[3]/line[1])))\n",
    "\n",
    "coeff_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fe908-e5b1-4bee-9e90-d81baf89e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will review the highest coefficients of each sector:\n",
    "# min: 21518 with 0.566 (la liga)\n",
    "# mid: 19694 with 0.423 (scotland)\n",
    "# max: 10257 with 0.0465 (serie a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74590078-15b6-45b5-a462-91a11de678f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rdds of most often min results and rdd of the most often max results\n",
    "\n",
    "init_df = matches_df.where(col(\"B365H\").isNotNull())\n",
    "min_df = init_df.where(init_df.league_id == 21518)\n",
    "max_df = init_df.where(init_df.league_id == 10257)\n",
    "\n",
    "def checkResult(x):\n",
    "    homeWinOdds = float(x.B365H)\n",
    "    tieOdds = float(x.B365D)\n",
    "    awayWinOdds = float(x.B365A)\n",
    "\n",
    "    homeGoals = int(x.home_team_goal)\n",
    "    awayGoals = int(x.away_team_goal)\n",
    "\n",
    "    list = [str(homeWinOdds), str(tieOdds), str(awayWinOdds) ]\n",
    "    float_arr = np.array(list, dtype=float)\n",
    "    maxVal = np.max(float_arr) \n",
    "\n",
    "    if (homeWinOdds == maxVal):\n",
    "        if (homeGoals > awayGoals):\n",
    "            return (\"HOME\", x.home_team_api_id, x.away_team_api_id)\n",
    "    if (tieOdds == maxVal):\n",
    "        if (homeGoals == awayGoals):\n",
    "            return (\"TIE\", x.home_team_api_id, x.away_team_api_id)\n",
    "    if (awayWinOdds == maxVal):\n",
    "        if (awayGoals > homeGoals):\n",
    "            return (\"AWAY\", x.home_team_api_id, x.away_team_api_id)\n",
    "\n",
    "max_matches_rdd = max_df.rdd.map(lambda x: checkResult(x))\n",
    "max_matches = max_matches_rdd.filter(lambda x: x is not None)\n",
    "\n",
    "min_matches_rdd = min_df.rdd.map(lambda x: checkResult(x))\n",
    "min_matches = min_matches_rdd.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc2b882-7630-419f-a718-c6c8ad5b828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_matches = max_matches.filter(lambda x: x[0] == 'HOME' or x[0] == 'AWAY')\n",
    "max_matches = max_matches.map(lambda x: (x[0], int(x[1])))\n",
    "\n",
    "min_matches = min_matches.filter(lambda x: x[0] == 'HOME' or x[0] == 'AWAY')\n",
    "min_matches = min_matches.map(lambda x: (x[0], int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199c70f-1aca-4776-8550-d8e873937f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_max_matches = max_matches.toDF()\n",
    "fin_min_matches = min_matches.toDF()\n",
    "\n",
    "_max = fin_max_matches.join(t_att_df, fin_max_matches._2 == t_att_df.team_api_id, 'inner')\n",
    "_min = fin_min_matches.join(t_att_df, fin_min_matches._2 == t_att_df.team_api_id, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778d280-5f33-4c64-8039-8bb32cac5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can compare the traits of teams who win matches with highest odds versus teams who win matches with lowest odds\n",
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d2484-ffb9-4c9b-a60f-4d0f46ce02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_max.select(mean(\"buildUpPlaySpeed\")).show()\n",
    "_min.select(mean(\"buildUpPlaySpeed\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d16083-e20b-4aae-8f9a-abac43971da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_max.select(mean(\"buildUpPlayPassing\")).show()\n",
    "_min.select(mean(\"buildUpPlayPassing\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa5bfe3-d70f-45b4-8c0a-c53303a73a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_max.select(mean(\"chanceCreationPassing\")).show()\n",
    "_max.select(mean(\"chanceCreationCrossing\")).show()\n",
    "_max.select(mean(\"chanceCreationShooting\")).show()\n",
    "\n",
    "_min.select(mean(\"chanceCreationPassing\")).show()\n",
    "_min.select(mean(\"chanceCreationCrossing\")).show()\n",
    "_min.select(mean(\"chanceCreationShooting\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc7d8f-291a-4034-bba3-fb8b9afbbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "_max.select(mean(\"defencePressure\")).show()\n",
    "_max.select(mean(\"defenceAggression\")).show()\n",
    "_max.select(mean(\"defenceTeamWidth\")).show()\n",
    "\n",
    "_min.select(mean(\"defencePressure\")).show()\n",
    "_min.select(mean(\"defenceAggression\")).show()\n",
    "_min.select(mean(\"defenceTeamWidth\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c40b9e-61ec-4848-82fa-1847cee69628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see a clear disparity in the build up speed of a team who takes advantage of being an underdog versus the team who is expected to win.\n",
    "# the build up speed is nearly 8 points higher, showing that teams who often win from underdog positions are playing the ball quickly, likely in a counter attacking motion, while the build up speed of expected winners are considerably more patient\n",
    "\n",
    "# not as large of a disparity in the teams orientation of pass vs. dribble. as such, we can assume that this varies more between teams whether they are expected winners or underdogs\n",
    "\n",
    "# we can see that the more expected teams generate more chances through all outputs. however the underdogs tend to create better chances via shooting, likely intending to take advantage of their slim chances. \n",
    "# we can assume a team who sits back, counters and takes their chances will have a good chance of achieving a win with great odds if they are near these metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041a594-bf9c-463f-afe6-6f9da4c46488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "init_df = matches_df.where(col(\"B365H\").isNotNull())\n",
    "min_df = init_df.where(init_df.league_id == 21518)\n",
    "max_df = init_df.where(init_df.league_id == 10257)\n",
    "\n",
    "def result(x):\n",
    "    homeWinOdds = float(x.B365H)\n",
    "    tieOdds = float(x.B365D)\n",
    "    awayWinOdds = float(x.B365A)\n",
    "\n",
    "    homeGoals = int(x.home_team_goal)\n",
    "    awayGoals = int(x.away_team_goal)\n",
    "\n",
    "    list = [str(homeWinOdds), str(tieOdds), str(awayWinOdds) ]\n",
    "    float_arr = np.array(list, dtype=float)\n",
    "    maxVal = np.max(float_arr) \n",
    "\n",
    "    if (homeWinOdds == maxVal):\n",
    "        if (homeGoals > awayGoals):\n",
    "            return (\"HOME\", x.home_team_api_id, x.away_team_api_id)\n",
    "    if (tieOdds == maxVal):\n",
    "        if (homeGoals == awayGoals):\n",
    "            return (\"TIE\", x.home_team_api_id, x.away_team_api_id)\n",
    "    if (awayWinOdds == maxVal):\n",
    "        if (awayGoals > homeGoals):\n",
    "            return (\"AWAY\", x.away_team_api_id, x.home_team_api_id)\n",
    "    \n",
    "\n",
    "max_matches_rdd = max_df.rdd.map(lambda x: result(x))\n",
    "max_matches = max_matches_rdd.filter(lambda x: x is not None)\n",
    "\n",
    "min_matches_rdd = min_df.rdd.map(lambda x: result(x))\n",
    "min_matches = min_matches_rdd.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc93566-afdf-47cc-b878-c452c2bb6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_df = min_matches.toDF()\n",
    "t2_df = max_matches.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87143c-5577-43da-a3b8-126698cf3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = []\n",
    "el2 = []\n",
    "\n",
    "# we need to take the dataframe of all the teams in this league as well as the teams who have achieved these results and put a column with a 1 for said team if they were able to achieve winning at lowest odds at some point\n",
    "for row in t1_df.rdd.collect():\n",
    "    el.append(row['_2'])\n",
    "    el.append(row['_3'])\n",
    "    \n",
    "for row in t2_df.rdd.collect():\n",
    "    el2.append(row['_2'])\n",
    "    el2.append(row['_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ea765-62e3-40fd-b0a3-c0ffaa01adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_min_teams = list(set(el))\n",
    "arr_max_teams = list(set(el2))\n",
    "\n",
    "rdd1 = sc.parallelize(arr_min_teams)\n",
    "rdd2 = sc.parallelize(arr_max_teams)\n",
    "\n",
    "df1 = rdd1.map(lambda x: (x, )).toDF()\n",
    "df1 = df1.withColumnRenamed(\"_1\", \"team_api_id\")\n",
    "df2 = rdd2.map(lambda x: (x, )).toDF()\n",
    "df2 = df2.withColumnRenamed(\"_1\", \"team_api_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e3c39-12eb-45e3-a9a8-28ee22c9ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "# create schema to resemble the features of team identity\n",
    "schema = StructType([\n",
    "  StructField('team_api_id', IntegerType(), True),\n",
    "  StructField('buildUpPlaySpeed', IntegerType(), True),\n",
    "  StructField('buildUpPlayPassing', IntegerType(), True),\n",
    "  StructField('chanceCreationPassing', IntegerType(), True),\n",
    "  StructField('chanceCreationCrossing', IntegerType(), True),\n",
    "  StructField('chanceCreationShooting', IntegerType(), True),\n",
    "  StructField('defencePressure', IntegerType(), True),\n",
    "  StructField('defenceAggression', IntegerType(), True),\n",
    "  StructField('defenceTeamWidth', IntegerType(), True),\n",
    "])\n",
    "fin_min_att_df = spark.createDataFrame([], schema)\n",
    "fin_max_att_df = spark.createDataFrame([], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6683a-b7bb-4db4-8742-cb8921e1eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "init_df = matches_df.where(col(\"B365H\").isNotNull())\n",
    "min_df = init_df.where(init_df.league_id == 21518)\n",
    "max_df = init_df.where(init_df.league_id == 10257)\n",
    "\n",
    "def check(x):\n",
    "    homeWinOdds = float(x.B365H)\n",
    "    tieOdds = float(x.B365D)\n",
    "    awayWinOdds = float(x.B365A)\n",
    "\n",
    "    homeGoals = int(x.home_team_goal)\n",
    "    awayGoals = int(x.away_team_goal)\n",
    "\n",
    "    list = [str(homeWinOdds), str(tieOdds), str(awayWinOdds) ]\n",
    "    float_arr = np.array(list, dtype=float)\n",
    "    maxVal = np.max(float_arr) \n",
    "\n",
    "    if (homeWinOdds == maxVal):\n",
    "        if (homeGoals > awayGoals):\n",
    "            return (x.home_team_api_id, 1)\n",
    "    if (tieOdds == maxVal):\n",
    "        if (homeGoals == awayGoals):\n",
    "            return (x.home_team_api_id, 1)\n",
    "    if (awayWinOdds == maxVal):\n",
    "        if (awayGoals > homeGoals):\n",
    "            return ( x.away_team_api_id, 1)\n",
    "    \n",
    "\n",
    "rdd1 = max_df.rdd.map(lambda x: check(x))\n",
    "rdd_max = rdd1.filter(lambda x: x is not None)\n",
    "\n",
    "rdd2 = min_df.rdd.map(lambda x: check(x))\n",
    "rdd_min = rdd2.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5221a-bf10-4714-9efc-3edcb7ef9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the list of teams who achieved success with lowest/max odds in respective league\n",
    "\n",
    "min_rdd = rdd_min.reduceByKey(lambda x, y: x+y)\n",
    "min_rdd = min_rdd.toDF()\n",
    "\n",
    "max_rdd = rdd_max.reduceByKey(lambda x, y: x+y)\n",
    "max_rdd = max_rdd.toDF()\n",
    "\n",
    "min_rdd = min_rdd.withColumnRenamed('_1', 'team_api_id')\n",
    "max_rdd = max_rdd.withColumnRenamed('_1', 'team_api_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ac30a-9507-4cad-8a9e-31f15ba8ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808d34c-358a-4b6e-9d25-5da29b55a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can join these dataframes with the team attributes dataframe on each team ID\n",
    "df_min_atts = df1.join(t_att_df, \"team_api_id\")\n",
    "columns = ['team_fifa_api_id', 'date','id', 'buildUpPlaySpeedClass', 'buildUpPlayDribbling', 'buildUpPlayDribblingClass', 'buildUpPlayPassingClass', 'buildUpPlayPositioningClass', 'chanceCreationPassingClass', 'chanceCreationCrossingClass', 'chanceCreationShootingClass', 'chanceCreationPositioningClass', 'defencePressureClass', 'defenceAggressionClass', 'defenceTeamWidthClass', 'defenceDefenderLineClass']\n",
    "df_min_atts = df_min_atts.drop(*columns)\n",
    "\n",
    "df_min_atts = df_min_atts.withColumn(\"buildUpPlaySpeed\", col(\"buildUpPlaySpeed\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"buildUpPlayPassing\", col(\"buildUpPlayPassing\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"chanceCreationPassing\", col(\"chanceCreationPassing\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"chanceCreationCrossing\", col(\"chanceCreationCrossing\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"chanceCreationShooting\", col(\"chanceCreationShooting\").cast(IntegerType()))  \n",
    "df_min_atts = df_min_atts.withColumn(\"defencePressure\", col(\"defencePressure\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"defenceAggression\", col(\"defenceAggression\").cast(IntegerType()))    \n",
    "df_min_atts = df_min_atts.withColumn(\"defenceTeamWidth\", col(\"defenceTeamWidth\").cast(IntegerType()))    \n",
    "\n",
    "df_min_atts = df_min_atts.groupBy('team_api_id').mean('buildUpPlaySpeed', 'buildUpPlayPassing', 'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting', 'defencePressure', 'defenceAggression', 'defenceTeamWidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ed584-7661-4abd-a501-37956c0ce53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can clearly see from above that some teams achieve this win from lower odds than others: we will give teams with a value greater than 30. everyone else will get 0, then we can split for training and testing\n",
    "df_min_atts = df_min_atts.join(min_rdd, df_min_atts.team_api_id == min_rdd.team_api_id)\n",
    "df_min_atts = df_min_atts.withColumn(\"val\", when(df_min_atts._2 >= 20, lit(1)).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf84a1-6f58-4243-9fd5-25a80df9cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2 = ['team_api_id', '_2']\n",
    "df_min_atts = df_min_atts.drop(*columns2)\n",
    "\n",
    "df_min_atts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f93888-1269-4bf0-8293-159f2d6e95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_atts = df2.join(t_att_df, \"team_api_id\")\n",
    "columns = ['team_fifa_api_id', 'date','id', 'buildUpPlaySpeedClass', 'buildUpPlayDribbling', 'buildUpPlayDribblingClass', 'buildUpPlayPassingClass', 'buildUpPlayPositioningClass', 'chanceCreationPassingClass', 'chanceCreationCrossingClass', 'chanceCreationShootingClass', 'chanceCreationPositioningClass', 'defencePressureClass', 'defenceAggressionClass', 'defenceTeamWidthClass', 'defenceDefenderLineClass']\n",
    "df_max_atts = df_max_atts.drop(*columns)\n",
    "\n",
    "df_max_atts = df_max_atts.withColumn(\"buildUpPlaySpeed\", col(\"buildUpPlaySpeed\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"buildUpPlayPassing\", col(\"buildUpPlayPassing\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"chanceCreationPassing\", col(\"chanceCreationPassing\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"chanceCreationCrossing\", col(\"chanceCreationCrossing\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"chanceCreationShooting\", col(\"chanceCreationShooting\").cast(IntegerType()))  \n",
    "df_max_atts = df_max_atts.withColumn(\"defencePressure\", col(\"defencePressure\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"defenceAggression\", col(\"defenceAggression\").cast(IntegerType()))    \n",
    "df_max_atts = df_max_atts.withColumn(\"defenceTeamWidth\", col(\"defenceTeamWidth\").cast(IntegerType()))    \n",
    "\n",
    "\n",
    "df_max_atts = df_max_atts.groupBy('team_api_id').mean('buildUpPlaySpeed', 'buildUpPlayPassing', 'chanceCreationPassing', 'chanceCreationCrossing', 'chanceCreationShooting', 'defencePressure', 'defenceAggression', 'defenceTeamWidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f92b0-dce9-4a38-aca0-41e761f7a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the same fashion for max atts, we will take the teams who achieved this result >= 20 times\n",
    "# teams: 9857, 8551, 8530, 8600, 10167, 8535, 8540, 9882, 9888, 8543, 8529, 8533, 10233, 8524, 7943\n",
    "df_max_atts = df_max_atts.join(max_rdd, df_max_atts.team_api_id == max_rdd.team_api_id)\n",
    "df_max_atts = df_max_atts.withColumn(\"val\", when(df_max_atts._2 >= 20, lit(1)).otherwise(lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0714a-5e3f-476b-b882-1a3eee83844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2 = ['team_api_id', '_2']\n",
    "df_max_atts = df_max_atts.drop(*columns2)\n",
    "\n",
    "df_max_atts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40dd66-25a3-47e5-9056-549d8094cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['avg(buildUpPlaySpeed)', 'avg(buildUpPlayPassing)', 'avg(chanceCreationPassing)', 'avg(chanceCreationCrossing)', 'avg(chanceCreationShooting)', 'avg(defencePressure)', 'avg(defenceAggression)', 'avg(defenceTeamWidth)'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27967ed-90ad-4ac6-9cf8-d17683c3292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_atts = assembler.transform(df_max_atts)\n",
    "df_min_atts = assembler.transform(df_min_atts)\n",
    "\n",
    "fin_max_data = df_max_atts.select('features', 'val')\n",
    "fin_min_data = df_min_atts.select('features', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6ba5d-4dbc-4cab-9f6d-72938200ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_df, min_test_df = df_min_atts.randomSplit(weights=[0.7,0.3], seed=100)\n",
    "max_train_df, max_test_df = df_max_atts.randomSplit(weights=[0.7,0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252e5d3-7686-4ba1-88f3-b4940dad6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220d3d9-d3d6-412d-9946-d3f19b8cb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min = LinearRegression(featuresCol=\"features\", labelCol=\"val\", predictionCol=\"predicted_val\")\n",
    "lr_model_min = lr_min.fit(min_train_df)\n",
    "\n",
    "lr_max = LinearRegression(featuresCol=\"features\", labelCol=\"val\", predictionCol=\"predicted_val\")\n",
    "lr_model_max = lr_max.fit(max_train_df)\n",
    "\n",
    "\n",
    "min_predictions = lr_model_min.transform(min_test_df)\n",
    "max_predictions = lr_model_max.transform(max_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a86019-b8f0-4715-95c4-47107630e3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_min = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"rmse\")\n",
    "rmse_min = evaluator_min.evaluate(min_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse_min))\n",
    "\n",
    "evaluator_r2_min = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"r2\")\n",
    "r2_min = evaluator_r2_min.evaluate(min_predictions)\n",
    "print(\"R-squared (R2) on test data: {:.3f}\".format(r2_min))\n",
    "\n",
    "\n",
    "evaluator_max = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"rmse\")\n",
    "rmse_max = evaluator_max.evaluate(max_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data: {:.3f}\".format(rmse_max))\n",
    "\n",
    "evaluator_r2_max = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"r2\")\n",
    "r2_max = evaluator_r2_max.evaluate(max_predictions)\n",
    "print(\"R-squared (R2) on test data: {:.3f}\".format(r2_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c43bf-833c-4a94-8f32-8305fae841b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"mse\")\n",
    "mse_min = evaluator.evaluate(min_predictions)\n",
    "print(\"Mean Squared Error (RMSE) on test data: {:.3f}\".format(mse_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396d886-ab0b-40c1-9c0e-30cc26ad6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"val\", predictionCol=\"predicted_val\", metricName=\"mse\")\n",
    "mse_max = evaluator.evaluate(max_predictions)\n",
    "print(\"Mean Squared Error (RMSE) on test data: {:.3f}\".format(mse_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff7c83-0197-49e3-a3df-fb9ad8848521",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_min = lr_model_min.coefficients\n",
    "intercept_min = lr_model_min.intercept\n",
    "\n",
    "print(\"Coefficients (min): \", coefficients_min)\n",
    "print(\"Intercept (min): {:.3f}\".format(intercept_min))\n",
    "\n",
    "\n",
    "coefficients_max = lr_model_max.coefficients\n",
    "intercept_max = lr_model_max.intercept\n",
    "\n",
    "print(\"Coefficients (max): \", coefficients_max)\n",
    "print(\"Intercept (max): {:.3f}\".format(intercept_max))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
